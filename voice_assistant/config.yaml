# Voice Assistant Configuration

system:
  wake_word_engine: "openwakeword" # Options: porcupine, openwakeword
  stt_engine: "vosk"
  tts_engine: "piper"
  llm_provider: "groq" # Options: lan, groq, gemini

audio:
  input_device_index: null # Auto-detect
  output_device_index: null # Auto-detect
  sample_rate: 16000
  channels: 1

wakeword:
  openwakeword:
    model_paths: ["resources/models/hey_jarvis_v0.1.tflite"]
    inference_framework: "tflite"
  porcupine:
    access_key: "${PORCUPINE_ACCESS_KEY}"
    keywords: ["jarvis"]
stt:
  vosk:
    model_path: "resources/models/vosk-model-small-en-us-0.15"

tts:
  piper:
    model_path: "resources/models/en_US-lessac-medium.onnx"
    piper_binary: "bin/piper/piper"
    voice: "en_US-lessac-medium"

llm:
  groq:
    api_key: "${GROQ_API_KEY}"
    model: "llama-3.3-70b-versatile"  # Updated to current model
  lan:
    base_url: "http://localhost:11434" # Ollama default
    model: "llama3"
  gemini:
    api_key: "${GEMINI_API_KEY}"
    model: "gemini-1.5-flash"
